---
title: "R Notebook"
output: html_notebook
---

```{r}
# packages used
library(tidyverse)
```


```{r}
# read data
imdb <- read.csv("imdb_top_1000.csv")
head(imdb)

# remove commas from Gross variable
imdb <- imdb %>%
  mutate(Gross = gsub(pattern = "[,]", replacement = "", Gross))

# make Gross numeric and remove NAs
imdb$Gross <- as.numeric(imdb$Gross)
imdb <- na.omit(imdb)
```

## Question 1

a.

```{r}
# fit IMDB_Rating and Gross to linear model
gross_imdb <- lm(IMDB_Rating ~ Gross, data = imdb)
summary(gross_imdb)
```

```{r}
# fit IMDB_Rating and Meta_score to linear model
meta_imdb <- lm(IMDB_Rating ~ Meta_score, data = imdb)
summary(meta_imdb)
```

```{r}
# predict IMDB Rating from gross (model 1)
Y1 <- predict(gross_imdb)
E1 <- mean((imdb$IMDB_Rating - Y1)^2)

# predict IMDB Rating from meta score (model 2)
Y2 <- predict(meta_imdb)
E2 <- mean((imdb$IMDB_Rating - Y2)^2)
c(E1,E2)
```

```{r}
# leave-one-out cross validation

#Initialize
N <- nrow(imdb)
predictors <- imdb[c("Gross","Meta_score")]
E_m1 <- numeric(N)
E_m2 <- numeric(N)
# CV Loop
for (i in 1:N)
{
  # Fit the models without the i^th data point
  m1_i <- lm(IMDB_Rating ~ Gross, data = imdb[-i,])
  m2_i <- lm(IMDB_Rating ~ Meta_score, data = imdb[-i,])
  # Predict CHD for the unobserved data point i
  Y1 <- predict(m1_i, newdata = predictors[i,])
  Y2 <- predict(m2_i, newdata = predictors[i,])
  # Compute the error
  E_m1[i] <- (imdb$IMDB_Rating[i] - Y1)^2
  E_m2[i] <- (imdb$IMDB_Rating[i] - Y2)^2
}

```

```{r}
c(mean(E_m1),mean(E_m2))

```

b.

```{r}
# fit Meta_score and Gross to linear model
gross_meta <- lm(Meta_score ~ Gross, data = imdb)
summary(gross_meta)
```

```{r}
# fit Meta_score and IMDB_Rating to linear model
imdb_meta <- lm(Meta_score ~ IMDB_Rating, data = imdb)
summary(imdb_meta)
```

```{r}
# predict meta score from gross (model 1)
Y1 <- predict(gross_meta)
E1 <- mean((imdb$Meta_score - Y1)^2)

# predict meta score from imdb rating (model 2)
Y2 <- predict(imdb_meta)
E2 <- mean((imdb$Meta_score - Y2)^2)
c(E1,E2)
```

```{r}
# leave-one-out cross validation

#Initialize
N <- nrow(imdb)
predictors <- imdb[c("Gross","IMDB_Rating")]
E_m1 <- numeric(N)
E_m2 <- numeric(N)
# CV Loop
for (i in 1:N)
{
  # Fit the models without the i^th data point
  m1_i <- lm(Meta_score ~ Gross, data = imdb[-i,])
  m2_i <- lm(Meta_score ~ IMDB_Rating, data = imdb[-i,])
  # Predict CHD for the unobserved data point i
  Y1 <- predict(m1_i, newdata = predictors[i,])
  Y2 <- predict(m2_i, newdata = predictors[i,])
  # Compute the error
  E_m1[i] <- (imdb$Meta_score[i] - Y1)^2
  E_m2[i] <- (imdb$Meta_score[i] - Y2)^2
}

```

```{r}
c(mean(E_m1),mean(E_m2))

```

## Question 2

...

## Question 3

```{r}
# Observed Test Statistic
Tobs <- abs(cor(imdb$IMDB_Rating, imdb$Meta_score))
#Monte Carlo
K <- 10000
# number of permutations used
Tperm <- numeric(K)
for (i in 1:K)
  {
  imdb_i <- sample(imdb$IMDB_Rating)
  meta_i <- sample(imdb$Meta_score)
  Tperm[i] <- abs(cor(imdb_i, meta_i))
  }

hist(Tperm, breaks=50)
abline(v=Tobs, lwd=3, col = 'red')

```

```{r}
mean(Tperm > Tobs)

```






